/*
*************************************************************************************************************************************
*************************************************************************************************************************************
********************* Step 0: Create Data Lake												***************************************
*************************************************************************************************************************************
*************************************************************************************************************************************
*/


--THIS IS DONE ON API UPLOAD SNA
-- read from the public s3 file. Then write to the folder structure.
-- SELECT * FROM readJSON(s3), write to paritioned BY year/month/date

/*
*************************************************************************************************************************************
*************************************************************************************************************************************
********************* Step 1: Read from Data Lake												***************************************
*************************************************************************************************************************************
*************************************************************************************************************************************
*/

-- Step 1: read from data lake

CREATE OR REPLACE TABLE data_lake_tikTok AS
SELECT 
    *
FROM read_ndjson(
    '${s3BucketRoot}/tenants/tenantid=${tenantId}/tablename=tikTok/*/*.jsonl.gz',
    hive_partitioning = true
)
WHERE CAST(date AS DATE) BETWEEN DATE '${startDate}' AND DATE '${endDate}';





/*
*************************************************************************************************************************************
*************************************************************************************************************************************
********************* Step 2: Create Models	(no files here below)									***************************************
*************************************************************************************************************************************
*************************************************************************************************************************************
*/

-- create orders
CREATE OR REPLACE TABLE model_tikTok AS
SELECT 
    spend::DOUBLE AS spend,
    clicks::DOUBLE AS clicks,
    conversion::DOUBLE AS conversion,
    strftime(snapshotDate, '%Y-%m') AS iso_month,
    strftime(snapshotDate, '%Y') AS iso_year,
    strftime(snapshotDate, '%Y-%m-%d') AS iso_date,
    strftime(snapshotDate, '%G-W%V') AS iso_week
FROM data_lake_tikTok;


/*
*************************************************************************************************************************************
*************************************************************************************************************************************
********************* Step 3: WRITE TO OUTPUT TABLES											***************************************
*************************************************************************************************************************************
*************************************************************************************************************************************
*/

-- Step 3: output

--THESE VALUES ARE so SMALL

COPY model_tikTok TO '${s3BucketRoot}/tenants/tenantid=${tenantId}/transposed-output/tablename=socialMedia/model_tikTok.parquet'
(FORMAT parquet, COMPRESSION zstd);

--COPY model_tikTok TO '${s3BucketRoot}/tenants/tenantid=${tenantId}/transposed-output/tablename=model_tikTok'
--(FORMAT parquet, COMPRESSION zstd, PARTITION_BY (iso_month), OVERWRITE_OR_IGNORE TRUE, FILENAME_PATTERN 'part_{i}');


