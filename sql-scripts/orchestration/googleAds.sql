/*
*************************************************************************************************************************************
*************************************************************************************************************************************
********************* Step 0: Create Data Lake												***************************************
*************************************************************************************************************************************
*************************************************************************************************************************************
*/


--THIS IS DONE ON API UPLOAD SNA
-- read from the public s3 file. Then write to the folder structure.
-- SELECT * FROM readJSON(s3), write to paritioned BY year/month/date

/*
*************************************************************************************************************************************
*************************************************************************************************************************************
********************* Step 1: Read from Data Lake												***************************************
*************************************************************************************************************************************
*************************************************************************************************************************************
*/

-- Step 1: read from data lake

CREATE OR REPLACE TABLE data_lake_googleAds AS
SELECT 
    *
FROM read_ndjson(
    '${s3BucketRoot}/tenants/tenantid=${tenantId}/tablename=googleAds/*/*.jsonl.gz',
    hive_partitioning = true
)
WHERE CAST(date AS DATE) BETWEEN DATE '${startDate}' AND DATE '${endDate}';




/*
*************************************************************************************************************************************
*************************************************************************************************************************************
********************* Step 2: Create Models	(no files here below)									***************************************
*************************************************************************************************************************************
*************************************************************************************************************************************
*/

-- create orders
CREATE OR REPLACE TABLE model_googleAds AS
SELECT 
    metrics.costMicros::DOUBLE AS costMicros,
    metrics.clicks::DOUBLE AS clicks,
    metrics.conversions::DOUBLE AS conversions,
	strftime(snapshotDate, '%Y-%m') AS iso_month,
	strftime(snapshotDate, '%Y') AS iso_year,
    strftime(snapshotDate, '%Y-%m-%d') AS iso_date,
    strftime(snapshotDate, '%G-W%V') AS iso_week
FROM data_lake_googleAds;

/*
*************************************************************************************************************************************
*************************************************************************************************************************************
********************* Step 3: WRITE TO OUTPUT TABLES											***************************************
*************************************************************************************************************************************
*************************************************************************************************************************************
*/
-- Step 3: output

COPY model_googleAds TO '${s3BucketRoot}/tenants/tenantid=${tenantId}/transposed-output/tablename=socialMedia/model_googleAds.parquet'
(FORMAT parquet, COMPRESSION zstd);

--
--COPY model_googleAds TO '${s3BucketRoot}/tenants/tenantid=${tenantId}/transposed-output/tablename=model_googleAds'
--(FORMAT parquet, COMPRESSION zstd, PARTITION_BY (iso_year), OVERWRITE_OR_IGNORE TRUE, FILENAME_PATTERN 'part_{i}');
--
--